{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25af8812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 14:03:55.126202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 14:04:02.879173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-01 14:04:03.013326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-01 14:04:03.013350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fbafc635c74c00b1e123a51b8fe047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f51d5a066f3425daac0fdd30d641062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea1a3d801c742c0870f7fd5ab128736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/352M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "cache_dir = \"/mnt/sdb1tb/ege/ceng502\"\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch32-224-in21k', cache_dir=cache_dir)\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch32-224-in21k', cache_dir=cache_dir)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_state = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6cbc1147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8c9f80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 768])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7a40404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=768, bias=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[0].attention.attention.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1604f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTLayer(\n",
       "  (attention): ViTAttention(\n",
       "    (attention): ViTSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (output): ViTSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): ViTIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): ViTOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "396f5dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.cls_token\n",
      "embeddings.position_embeddings\n",
      "embeddings.patch_embeddings.projection.weight\n",
      "embeddings.patch_embeddings.projection.bias\n",
      "encoder.layer.0.attention.attention.query.weight\n",
      "encoder.layer.0.attention.attention.query.bias\n",
      "encoder.layer.0.attention.attention.key.weight\n",
      "encoder.layer.0.attention.attention.key.bias\n",
      "encoder.layer.0.attention.attention.value.weight\n",
      "encoder.layer.0.attention.attention.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.layernorm_before.weight\n",
      "encoder.layer.0.layernorm_before.bias\n",
      "encoder.layer.0.layernorm_after.weight\n",
      "encoder.layer.0.layernorm_after.bias\n",
      "encoder.layer.1.attention.attention.query.weight\n",
      "encoder.layer.1.attention.attention.query.bias\n",
      "encoder.layer.1.attention.attention.key.weight\n",
      "encoder.layer.1.attention.attention.key.bias\n",
      "encoder.layer.1.attention.attention.value.weight\n",
      "encoder.layer.1.attention.attention.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.layernorm_before.weight\n",
      "encoder.layer.1.layernorm_before.bias\n",
      "encoder.layer.1.layernorm_after.weight\n",
      "encoder.layer.1.layernorm_after.bias\n",
      "encoder.layer.2.attention.attention.query.weight\n",
      "encoder.layer.2.attention.attention.query.bias\n",
      "encoder.layer.2.attention.attention.key.weight\n",
      "encoder.layer.2.attention.attention.key.bias\n",
      "encoder.layer.2.attention.attention.value.weight\n",
      "encoder.layer.2.attention.attention.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.layernorm_before.weight\n",
      "encoder.layer.2.layernorm_before.bias\n",
      "encoder.layer.2.layernorm_after.weight\n",
      "encoder.layer.2.layernorm_after.bias\n",
      "encoder.layer.3.attention.attention.query.weight\n",
      "encoder.layer.3.attention.attention.query.bias\n",
      "encoder.layer.3.attention.attention.key.weight\n",
      "encoder.layer.3.attention.attention.key.bias\n",
      "encoder.layer.3.attention.attention.value.weight\n",
      "encoder.layer.3.attention.attention.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.layernorm_before.weight\n",
      "encoder.layer.3.layernorm_before.bias\n",
      "encoder.layer.3.layernorm_after.weight\n",
      "encoder.layer.3.layernorm_after.bias\n",
      "encoder.layer.4.attention.attention.query.weight\n",
      "encoder.layer.4.attention.attention.query.bias\n",
      "encoder.layer.4.attention.attention.key.weight\n",
      "encoder.layer.4.attention.attention.key.bias\n",
      "encoder.layer.4.attention.attention.value.weight\n",
      "encoder.layer.4.attention.attention.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.layernorm_before.weight\n",
      "encoder.layer.4.layernorm_before.bias\n",
      "encoder.layer.4.layernorm_after.weight\n",
      "encoder.layer.4.layernorm_after.bias\n",
      "encoder.layer.5.attention.attention.query.weight\n",
      "encoder.layer.5.attention.attention.query.bias\n",
      "encoder.layer.5.attention.attention.key.weight\n",
      "encoder.layer.5.attention.attention.key.bias\n",
      "encoder.layer.5.attention.attention.value.weight\n",
      "encoder.layer.5.attention.attention.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.layernorm_before.weight\n",
      "encoder.layer.5.layernorm_before.bias\n",
      "encoder.layer.5.layernorm_after.weight\n",
      "encoder.layer.5.layernorm_after.bias\n",
      "encoder.layer.6.attention.attention.query.weight\n",
      "encoder.layer.6.attention.attention.query.bias\n",
      "encoder.layer.6.attention.attention.key.weight\n",
      "encoder.layer.6.attention.attention.key.bias\n",
      "encoder.layer.6.attention.attention.value.weight\n",
      "encoder.layer.6.attention.attention.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.layernorm_before.weight\n",
      "encoder.layer.6.layernorm_before.bias\n",
      "encoder.layer.6.layernorm_after.weight\n",
      "encoder.layer.6.layernorm_after.bias\n",
      "encoder.layer.7.attention.attention.query.weight\n",
      "encoder.layer.7.attention.attention.query.bias\n",
      "encoder.layer.7.attention.attention.key.weight\n",
      "encoder.layer.7.attention.attention.key.bias\n",
      "encoder.layer.7.attention.attention.value.weight\n",
      "encoder.layer.7.attention.attention.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.layernorm_before.weight\n",
      "encoder.layer.7.layernorm_before.bias\n",
      "encoder.layer.7.layernorm_after.weight\n",
      "encoder.layer.7.layernorm_after.bias\n",
      "encoder.layer.8.attention.attention.query.weight\n",
      "encoder.layer.8.attention.attention.query.bias\n",
      "encoder.layer.8.attention.attention.key.weight\n",
      "encoder.layer.8.attention.attention.key.bias\n",
      "encoder.layer.8.attention.attention.value.weight\n",
      "encoder.layer.8.attention.attention.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.layernorm_before.weight\n",
      "encoder.layer.8.layernorm_before.bias\n",
      "encoder.layer.8.layernorm_after.weight\n",
      "encoder.layer.8.layernorm_after.bias\n",
      "encoder.layer.9.attention.attention.query.weight\n",
      "encoder.layer.9.attention.attention.query.bias\n",
      "encoder.layer.9.attention.attention.key.weight\n",
      "encoder.layer.9.attention.attention.key.bias\n",
      "encoder.layer.9.attention.attention.value.weight\n",
      "encoder.layer.9.attention.attention.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.layernorm_before.weight\n",
      "encoder.layer.9.layernorm_before.bias\n",
      "encoder.layer.9.layernorm_after.weight\n",
      "encoder.layer.9.layernorm_after.bias\n",
      "encoder.layer.10.attention.attention.query.weight\n",
      "encoder.layer.10.attention.attention.query.bias\n",
      "encoder.layer.10.attention.attention.key.weight\n",
      "encoder.layer.10.attention.attention.key.bias\n",
      "encoder.layer.10.attention.attention.value.weight\n",
      "encoder.layer.10.attention.attention.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.layernorm_before.weight\n",
      "encoder.layer.10.layernorm_before.bias\n",
      "encoder.layer.10.layernorm_after.weight\n",
      "encoder.layer.10.layernorm_after.bias\n",
      "encoder.layer.11.attention.attention.query.weight\n",
      "encoder.layer.11.attention.attention.query.bias\n",
      "encoder.layer.11.attention.attention.key.weight\n",
      "encoder.layer.11.attention.attention.key.bias\n",
      "encoder.layer.11.attention.attention.value.weight\n",
      "encoder.layer.11.attention.attention.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.layernorm_before.weight\n",
      "encoder.layer.11.layernorm_before.bias\n",
      "encoder.layer.11.layernorm_after.weight\n",
      "encoder.layer.11.layernorm_after.bias\n",
      "layernorm.weight\n",
      "layernorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    if name == \"embeddings.cls_token\":\n",
    "        cls_token = param\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8faa65ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_token.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db509b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4724e-01,  1.0381e-01, -4.9984e-02, -1.0894e-01,  2.0840e-01,\n",
       "         -5.9280e-02, -6.7109e-02, -1.2395e-01,  3.5361e-01,  3.1208e-01,\n",
       "          1.0147e-01,  3.2999e-02, -5.0150e-03, -8.4950e-02,  1.9849e-01,\n",
       "         -8.2933e-02,  8.3284e-04, -7.4282e-02,  2.0753e-01, -6.9254e-02,\n",
       "          8.6422e-02,  3.1460e-01,  5.1740e-01,  3.3572e-02,  5.0058e-02,\n",
       "         -1.0896e-01, -1.2060e-01,  9.1437e-02, -5.8499e-02,  2.3047e-01,\n",
       "         -2.3624e-01, -4.0661e-03, -1.5772e-01, -3.6367e-02, -3.4246e-01,\n",
       "         -7.6734e-02, -1.3804e-01, -6.3713e-02,  1.9820e-01, -1.1941e-04,\n",
       "          7.7860e-03, -1.6803e-02, -1.7929e-01, -2.2642e-01,  1.0151e-01,\n",
       "         -5.7987e-02, -5.5334e-02,  1.6411e-01, -4.0961e-02, -1.7172e-01,\n",
       "         -2.2321e-02, -5.6321e-02, -3.8074e-01, -3.5759e-01, -7.1236e-02,\n",
       "          2.8638e-01, -8.9613e-02, -2.3077e-01, -1.7144e-01,  2.5845e-01,\n",
       "         -6.5910e-02, -1.6854e-02, -1.1071e-01, -3.7961e-01,  8.9016e-03,\n",
       "         -6.9926e-03, -2.0502e-01,  9.7528e-02,  4.4951e-02,  9.3642e-02,\n",
       "         -1.1328e-01, -8.5342e-02,  1.0419e-01,  1.8140e-05,  2.8140e-02,\n",
       "          1.0852e-02, -4.4422e-01, -3.2590e-02, -1.0003e-01, -3.0705e-01,\n",
       "         -1.3955e-01,  1.5292e-02, -4.1670e-02,  1.8963e-01,  1.4366e-01,\n",
       "          1.4530e-01,  2.8805e-02,  1.2830e-02, -7.3265e-04, -1.1106e-01,\n",
       "         -3.8970e-02, -7.1472e-02,  6.3029e-02,  1.1124e-01, -4.6914e-02,\n",
       "         -9.1360e-02,  3.9720e-02,  2.0843e-01, -2.1216e-01, -6.3107e-02,\n",
       "          2.3312e-02,  1.3566e-01,  2.1608e-01,  1.3827e-01, -6.9957e-02,\n",
       "          1.8258e-01,  1.8724e-01,  2.3050e-01,  7.4768e-02,  8.2736e-02,\n",
       "         -1.3782e-01, -9.4660e-02, -7.1897e-02, -1.5020e-01, -4.6202e-02,\n",
       "          1.8800e-01,  1.6091e-02, -8.5501e-03,  2.1760e-01, -2.6288e-02,\n",
       "         -1.9595e-01, -1.1618e-01, -1.7265e-01, -1.8739e-01, -4.8044e-02,\n",
       "          2.4871e-01,  3.5853e-01, -2.2487e-02, -7.0679e-03,  7.1001e-02,\n",
       "          1.3857e-01,  3.6951e-02, -1.7100e-02, -8.9838e-02,  7.8360e-02,\n",
       "         -6.9534e-02,  2.2283e-01, -2.2891e-01, -5.2935e-02,  5.0949e-02,\n",
       "          2.9510e-01,  7.2498e-03,  8.5469e-02,  1.9256e-02, -1.0504e-01,\n",
       "         -2.0567e-01,  2.9300e-01,  1.4467e-01,  1.0522e-01, -2.1429e-01,\n",
       "         -1.1188e-01,  6.9058e-02,  1.3318e-01,  9.5351e-02, -1.7806e-01,\n",
       "          1.1816e-02, -2.1029e-01, -7.9590e-02, -2.3346e-02,  2.8477e-01,\n",
       "         -1.3977e-01,  9.9978e-02,  4.4527e-02, -2.9040e-02, -4.8998e-02,\n",
       "         -2.0668e-01, -4.7938e-02, -1.2329e-02,  2.7571e-01, -8.4853e-02,\n",
       "         -1.2492e-01, -1.9419e-01, -3.6467e-02,  9.2445e-02,  1.0462e-01,\n",
       "         -1.6328e-01, -6.4767e-02,  2.3814e-01, -6.9053e-02, -1.7097e-01,\n",
       "         -1.2875e-01,  2.6817e-01,  2.9402e-02,  1.1898e-02,  6.3644e-02,\n",
       "          3.1509e-02,  1.1709e-01, -1.3488e-01, -1.6686e-01,  3.1750e-01,\n",
       "         -1.0309e-01, -2.6657e-02, -1.2401e-01, -7.4053e-02, -2.5461e-01,\n",
       "         -6.3187e-02, -9.3450e-02, -2.1288e-01,  2.8429e-01, -1.0610e-01,\n",
       "          3.2043e-01, -1.1547e-01, -1.0030e-01,  5.4325e-02,  1.8378e-01,\n",
       "         -1.7417e-01,  1.0439e-01,  1.0409e-02, -5.2829e-02, -3.7551e-02,\n",
       "         -1.3327e-02, -3.0321e-01, -2.1395e-01, -1.7759e-01,  1.5246e-01,\n",
       "         -1.1532e-01, -7.1129e-02,  2.9641e-01,  1.3713e-01, -4.3520e-01,\n",
       "          1.1764e-01, -1.0747e-01, -2.3117e-01,  9.3935e-02,  7.2105e-02,\n",
       "         -3.4525e-01,  1.2673e-01,  3.6601e-02, -2.4772e-01,  1.3168e-01,\n",
       "         -1.1345e-02, -2.6920e-01, -3.4321e-01, -1.9677e-01,  2.6344e-01,\n",
       "         -3.7771e-01, -3.2123e-02, -1.2353e-01,  1.8511e-01,  4.6045e-03,\n",
       "         -2.9786e-01,  6.8411e-02,  4.6681e-03,  1.6471e-01,  3.5000e-03,\n",
       "         -1.5106e-01, -2.0190e-01, -3.8628e-01,  1.4399e-01, -1.9468e-02,\n",
       "         -2.2769e-01,  2.9933e-02,  1.7647e-03, -6.1122e-02,  1.0609e-01,\n",
       "         -3.4218e-02,  4.4575e-01, -7.7491e-02, -2.2966e-01, -1.2457e-01,\n",
       "          1.1601e-01,  2.2350e-01, -4.2935e-02,  2.8625e-01, -2.1235e-01,\n",
       "          4.8131e-01,  2.4179e-03,  1.5700e-01, -1.6609e-02, -7.7582e-03,\n",
       "          1.7546e-01, -1.1482e-01,  3.0458e-01, -4.3661e-02, -6.5373e-02,\n",
       "         -1.3786e-01,  6.1699e-02, -1.6594e-01, -1.1585e-01,  1.6224e-02,\n",
       "         -2.2999e-01, -1.6343e-01, -3.4012e-02, -2.6540e-02, -3.9056e-01,\n",
       "          1.4335e-01,  9.0743e-02,  6.3514e-02, -2.4885e-01,  2.6995e-01,\n",
       "         -2.7844e-01,  1.2010e-01, -1.4239e-01,  7.3060e-04,  5.8261e-02,\n",
       "          1.8847e-02, -1.8112e-01, -1.9280e-01, -2.2904e-02,  2.2740e-01,\n",
       "          6.8675e-02,  8.6736e-03,  4.6185e-01, -7.7599e-02, -1.0948e-01,\n",
       "          3.9135e-02, -1.3457e-01,  1.7997e-01, -2.2598e-01,  2.0940e-01,\n",
       "          1.8352e-02, -1.3385e-01,  1.9376e-02,  1.4271e-01, -3.2502e-02,\n",
       "         -1.1659e-01,  2.1219e-01, -1.1446e-01,  8.0919e-02, -2.2745e-02,\n",
       "          1.1849e-01,  3.0973e-01, -5.6102e-02, -1.5147e-01,  1.3978e-01,\n",
       "         -2.2302e-01, -1.5308e-01,  2.0180e-01, -4.9713e-02, -2.7553e-02,\n",
       "         -2.7009e-01, -1.1623e-01, -3.2519e-02,  2.2057e-02, -1.4179e-02,\n",
       "         -3.1232e-01, -1.5807e-01,  2.7109e-01, -1.8501e-01, -9.5140e-02,\n",
       "         -3.5526e-01,  6.5307e-02,  1.5205e-02, -1.1565e-01,  2.5620e-03,\n",
       "         -5.4563e-02, -1.5219e-01, -2.2301e-01,  2.8136e-01,  2.1758e-02,\n",
       "         -1.9914e-01, -1.7368e-01, -9.2404e-02, -2.1341e-01,  1.2260e-02,\n",
       "         -5.4869e-02, -2.6762e-01,  1.0709e-01, -6.4957e-02, -1.5238e-01,\n",
       "         -1.5348e-01,  2.9779e-02,  5.3809e-02, -1.5696e-01, -4.7748e-03,\n",
       "          1.9726e-01, -1.9788e-01,  2.4394e-01, -5.3212e-02, -1.8964e-03,\n",
       "          2.1638e-01, -4.4736e-01,  2.5391e-01, -6.9680e-02,  4.0846e-02,\n",
       "         -1.3587e-01,  1.5801e-02,  1.2509e-01, -1.0580e-01, -3.0906e-01,\n",
       "          5.2568e-02, -3.0916e-01,  6.5572e-02, -3.0513e-01, -9.1825e-02,\n",
       "          5.9270e-02, -3.4518e-02,  3.6145e-02,  2.1996e-01,  1.3125e-01,\n",
       "         -3.9535e-01, -1.3759e-01,  1.6067e-01, -1.6152e-01, -1.5127e-01,\n",
       "         -8.1750e-02,  1.3091e-01,  2.9212e-03,  6.5639e-02,  7.6880e-02,\n",
       "         -2.2500e-01,  1.7838e-01, -6.7497e-02, -9.7525e-02, -3.2926e-02,\n",
       "          1.8171e-01, -1.2631e-01, -1.7010e-01, -4.3903e-02,  5.1968e-02,\n",
       "         -6.7417e-02, -2.0936e-02, -9.9928e-02,  2.8168e-02, -2.2381e-01,\n",
       "         -2.7469e-01,  2.5657e-01, -6.4420e-02, -2.2510e-01, -9.8750e-02,\n",
       "         -1.2443e-01,  1.0357e-01, -1.2600e-01,  7.0177e-02, -2.7672e-02,\n",
       "          9.2256e-02, -4.3674e-03,  1.0160e-01,  2.0329e-02,  8.9128e-02,\n",
       "          8.1034e-02, -9.0637e-02,  1.9626e-01, -4.8278e-03,  1.5306e-01,\n",
       "         -3.4004e-01, -2.6286e-01, -3.0065e-01, -3.2209e-01,  2.1317e-01,\n",
       "         -1.5747e-01,  1.8678e-01, -4.7244e-02, -1.2644e-01, -3.3281e-01,\n",
       "         -6.3674e-02, -4.7050e-02,  2.7620e-01,  3.4487e-01, -1.1789e-01,\n",
       "         -1.0970e-01, -1.9094e-01, -1.0223e-02, -1.9452e-01,  1.1634e-02,\n",
       "         -7.8566e-02, -1.1166e-01, -3.4890e-02,  3.2106e-01,  1.3926e-01,\n",
       "         -8.6720e-02,  8.6343e-02,  1.3798e-01, -2.2296e-01, -1.1230e-01,\n",
       "          2.2135e-01, -7.6325e-02,  1.1717e-01,  3.0846e-01,  1.8858e-01,\n",
       "         -5.5334e-02,  8.7722e-02, -1.7001e-01,  3.2083e-02,  2.4689e-01,\n",
       "          1.9706e-01,  2.1698e-01,  1.0032e-01,  2.0485e-01, -6.0075e-02,\n",
       "         -2.5170e-01,  2.1497e-01,  1.8201e-01,  1.0202e-01, -2.7270e-01,\n",
       "         -1.7073e-02, -4.2764e-02, -3.4533e-01, -1.5707e-01,  1.2744e-03,\n",
       "          5.6173e-02, -2.4175e-01, -3.8845e-03,  6.2311e-03,  1.2538e-02,\n",
       "         -1.2843e-01, -2.7383e-01, -5.9277e-02,  8.8639e-02,  9.8388e-02,\n",
       "         -5.3924e-02, -3.5340e-02, -3.4775e-01,  6.2964e-02, -4.8292e-02,\n",
       "         -4.4533e-02, -1.5108e-02, -2.4411e-01, -4.3722e-01,  8.0699e-02,\n",
       "          1.1327e-01, -1.0482e-01, -3.0124e-02, -2.4588e-01, -1.4581e-01,\n",
       "          1.5630e-01, -2.6389e-01, -1.8819e-01,  7.4370e-02,  2.1147e-01,\n",
       "         -2.1049e-02, -1.3139e-01, -3.3719e-03, -2.4490e-01, -8.7113e-02,\n",
       "          2.4846e-02, -2.4229e-01, -2.4196e-02,  1.5199e-03,  5.4563e-02,\n",
       "         -8.7063e-02, -1.6167e-01,  9.3410e-02,  6.6287e-02, -3.0548e-02,\n",
       "         -4.3030e-01, -4.2902e-02,  3.2148e-03, -1.3763e-01,  2.7260e-01,\n",
       "          1.6791e-01,  8.6931e-02,  1.5185e-02,  1.3204e-01, -1.8655e-02,\n",
       "         -2.8575e-01, -2.0272e-02, -2.4065e-01, -4.8192e-02, -1.5560e-01,\n",
       "         -2.3616e-01,  4.7039e-03, -2.6960e-02,  2.5549e-01,  1.4869e-01,\n",
       "          1.4847e-02, -9.2216e-03,  2.8711e-01,  1.4806e-01, -1.5699e-01,\n",
       "          1.2531e-01, -2.7758e-01,  8.6085e-02,  3.2701e-01, -4.1741e-01,\n",
       "         -1.8955e-01, -7.7256e-02,  2.4382e-01,  1.1852e-01, -2.8340e-01,\n",
       "          1.0615e-01,  6.1805e-02, -8.8337e-02, -8.5460e-02, -2.5815e-01,\n",
       "         -2.4814e-01,  2.4655e-01, -9.9902e-02, -1.1751e-01, -3.6718e-02,\n",
       "          3.2267e-01, -1.1524e-02, -8.5800e-02, -4.5320e-02, -2.3803e-01,\n",
       "         -1.6717e-01,  7.2195e-02,  1.7097e-01,  7.7559e-02,  3.1716e-01,\n",
       "          1.4847e-01, -1.2190e-01, -3.0917e-01, -7.2097e-02, -9.3746e-02,\n",
       "          1.4402e-01,  4.1352e-01,  1.5461e-01,  1.3922e-01,  4.1190e-02,\n",
       "         -1.2001e-01,  7.4994e-02, -3.4740e-02, -2.5277e-01, -1.8821e-01,\n",
       "         -1.6195e-01, -1.2863e-01,  9.4321e-03,  1.0827e-01,  1.3507e-01,\n",
       "         -2.8678e-02,  8.3824e-02, -1.1004e-01, -2.0315e-01,  1.9237e-02,\n",
       "         -7.0410e-02, -2.2955e-02, -2.0947e-01,  6.9220e-03, -4.4978e-02,\n",
       "         -4.4394e-02, -3.0225e-01, -2.1712e-02, -7.6915e-04, -9.0343e-02,\n",
       "         -3.5472e-02,  1.4295e-01,  2.5204e-01,  1.0396e-01, -1.0556e-01,\n",
       "          4.0269e-02, -1.5260e-01, -4.0447e-01, -2.3196e-01, -7.6912e-02,\n",
       "          2.9023e-03, -1.0510e-02, -6.2171e-02,  4.2798e-02,  2.2341e-02,\n",
       "         -1.3501e-01, -2.3664e-01, -2.4101e-01,  9.5518e-02, -4.4406e-02,\n",
       "         -1.3540e-01,  2.1748e-01, -1.1393e-02, -5.1312e-02,  2.7122e-02,\n",
       "          3.4375e-03, -1.5570e-01,  1.5189e-01,  5.2668e-02,  1.0279e-01,\n",
       "         -2.7103e-02, -2.1468e-01,  7.1487e-02,  1.3261e-01, -2.9919e-01,\n",
       "         -1.4407e-02,  1.0767e-01,  1.3190e-01,  3.9307e-01,  1.6220e-01,\n",
       "          8.2415e-02,  1.6664e-01, -7.1291e-02,  2.1403e-01, -2.4146e-01,\n",
       "          5.0819e-01, -1.7325e-01, -3.8449e-01, -9.9681e-02, -1.5523e-02,\n",
       "          5.2212e-02, -4.4570e-02, -1.4900e-01, -6.0039e-02, -1.0204e-01,\n",
       "          2.7494e-02, -1.3360e-01, -1.3108e-01, -1.2857e-01, -3.2170e-02,\n",
       "          1.1254e-02,  5.4609e-02,  3.3739e-01,  5.7322e-03, -1.6969e-01,\n",
       "         -3.7491e-01, -1.2988e-01, -8.6439e-02, -4.3736e-02,  1.0294e-01,\n",
       "         -1.8267e-01, -7.3565e-03,  1.2589e-01,  2.9856e-01, -1.4052e-01,\n",
       "         -2.7693e-01, -3.1116e-01,  8.7889e-02, -1.2166e-01,  1.5292e-01,\n",
       "          2.4847e-01,  4.8929e-02,  1.8243e-02, -2.0749e-01, -1.8929e-01,\n",
       "          7.0739e-02,  4.8908e-02,  1.1506e-01, -2.9642e-01, -8.4649e-02,\n",
       "         -4.2733e-02,  2.9307e-01, -2.6975e-01,  3.3310e-01,  1.1464e-01,\n",
       "         -1.1036e-01,  1.2499e-01,  1.8882e-03, -2.9146e-01, -1.5536e-01,\n",
       "         -6.5711e-02,  3.6831e-02,  1.1711e-01,  1.6439e-01,  5.8077e-02,\n",
       "         -4.4781e-02,  1.1859e-01, -5.4540e-04,  2.0537e-01,  1.1021e-01,\n",
       "          6.3248e-02, -8.7565e-02, -8.1781e-02,  8.7162e-02, -8.0209e-02,\n",
       "         -2.9685e-01, -1.0604e-01,  6.2865e-02,  4.6158e-02, -1.4009e-01,\n",
       "          2.1422e-02,  1.6680e-01,  1.3005e-01,  1.4823e-01, -2.1939e-01,\n",
       "         -4.1165e-01,  1.0121e-01, -1.2895e-01, -1.2350e-01, -8.0886e-02,\n",
       "         -2.2040e-01,  1.5294e-01, -1.0671e-01,  1.8550e-01, -2.3243e-01,\n",
       "         -1.0384e-01,  1.0366e-01, -2.5488e-01, -5.0845e-02, -2.1569e-01,\n",
       "         -3.1831e-01,  1.7473e-01,  6.0901e-02]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd09e88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTPooler(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef87b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
