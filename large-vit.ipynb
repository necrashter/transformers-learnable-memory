{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb90d44e",
   "metadata": {},
   "source": [
    "<center><h1>Fine-tuning Image Transformers using Learnable Memory</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069072db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Built-in IPython extension to reload modules when updated.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25af8812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 14:31:35.334417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 14:31:36.581054: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory\n",
      "2023-06-08 14:31:36.582035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory\n",
      "2023-06-08 14:31:36.582047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import transformers\n",
    "from transformers import ViTModel, ViTConfig, ViTForImageClassification\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "\n",
    "device = \"cuda:0\"\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "print(f\"Random seed set as {seed}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directories for cache and datasets\n",
    "home_dir = \"/hdd/ege\"\n",
    "cache_dir = os.path.join(home_dir, \"ceng502\")\n",
    "datasets_dir = os.path.join(home_dir, \"datasets\")\n",
    "\n",
    "# Uncomment if you don't want to see warnings\n",
    "# transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b14a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_model(\n",
    "        model_name = 'google/vit-base-patch32-224-in21k',\n",
    "        num_classes = 100,\n",
    "        ):\n",
    "    config = ViTConfig.from_pretrained(model_name, num_labels=num_classes, cache_dir=cache_dir)\n",
    "    model = ViTForImageClassification.from_pretrained(model_name, config=config, cache_dir=cache_dir)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda33444",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d95cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torchvision.transforms.functional import to_pil_image, to_grayscale\n",
    "\n",
    "# Define a transformation that converts images to RGB\n",
    "def to_rgb(image):\n",
    "    image = to_pil_image(image)\n",
    "    return ToTensor()(image.convert('RGB'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346e12bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# CIFAR100\n",
    "cifar100_train_dataset = datasets.CIFAR100(root=datasets_dir, train=True, transform=transform, download=True)\n",
    "cifar100_train_loader = DataLoader(dataset=cifar100_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "cifar100_validation_dataset = datasets.CIFAR100(root=datasets_dir, train=False, transform=transform, download=True)\n",
    "cifar100_validation_loader = DataLoader(dataset=cifar100_validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "places_train_dataset = datasets.Places365(root=datasets_dir,small=True, split=\"train-standard\", transform=transform)#, download=True)\n",
    "places_train_loader = DataLoader(dataset=places_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "places_validation_dataset = datasets.Places365(root=datasets_dir,small=True, split=\"val\", transform=transform)#, download=True)\n",
    "places_validation_loader = DataLoader(dataset=places_validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    Lambda(to_rgb),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Download the entire dataset\n",
    "naturalist_dataset = datasets.INaturalist(root=datasets_dir, version=\"2017\", transform=transform)#, download=True)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "train_size = int(0.8 * len(naturalist_dataset))\n",
    "test_size = len(naturalist_dataset) - train_size\n",
    "naturalist_train_dataset, naturalist_test_dataset = torch.utils.data.random_split(naturalist_dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders for the training and test subsets\n",
    "naturalist_train_loader = DataLoader(dataset=naturalist_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "naturalist_test_loader = DataLoader(dataset=naturalist_test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dabb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of steps and warmup steps\n",
    "total_steps = 20\n",
    "warmup_steps = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690ff7a",
   "metadata": {},
   "source": [
    "# Training and Validation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5f578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear warmup\n",
    "def warmup_linear(step):\n",
    "    if step < warmup_steps:\n",
    "        return float(step) / float(max(1, warmup_steps))\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def train(model, parameters,\n",
    "          dataloader, valid_dataloader,\n",
    "          output_head=None,\n",
    "         total_steps = 20):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # SGD with Momentum optimizer\n",
    "    optimizer = optim.SGD(parameters, lr=0.1, momentum=0.9)\n",
    "    # Cosine learning rate schedule\n",
    "    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "    \n",
    "    warmup_scheduler = LambdaLR(optimizer, warmup_linear)\n",
    "\n",
    "    train_losses, valid_accuracy = [], []\n",
    "    for step in tqdm(range(total_steps), leave=False):\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, targets) in enumerate(tqdm(dataloader, leave=False)):\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            if output_head is not None:\n",
    "                outputs = outputs[output_head]\n",
    "            loss = criterion(outputs.logits, targets)\n",
    "            loss_val = loss.detach().cpu().item()\n",
    "            train_loss += loss_val\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            clip_grad_norm_(parameters, max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update learning rate\n",
    "            if step < warmup_steps:\n",
    "                warmup_scheduler.step()\n",
    "            else:\n",
    "                cosine_scheduler.step()\n",
    "                \n",
    "        epoch_loss = train_loss/len(dataloader)\n",
    "        print(f\"step {step} loss is {epoch_loss:.4f}\")\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        valid_acc = validate(model, valid_dataloader, output_head)\n",
    "        print(f\"step {step} valid acc is {valid_acc:.2f}\")\n",
    "        valid_accuracy.append(valid_acc)\n",
    "\n",
    "        #print(f\"Epoch {epoch + 1}/{num_epochs} loss: {train_loss}\")\n",
    "    return train_losses, valid_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67536e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, output_head=None):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, targets in tqdm(dataloader, leave=False):\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            if output_head is not None:\n",
    "                outputs = outputs[output_head]\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24929fa",
   "metadata": {},
   "source": [
    "# Full Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1c848",
   "metadata": {},
   "source": [
    "plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_model()\n",
    "full_train, full_val = train(model, model.parameters(), cifar100_train_loader, cifar100_validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_full = validate(model, cifar100_validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a96e5a",
   "metadata": {},
   "source": [
    "# Class+Head Only Finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ee1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch32-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch32-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = pretrained_model()\n",
    "parameters = [model.vit.embeddings.cls_token] + list(model.classifier.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29137055",
   "metadata": {},
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if (\"classifier\" not in name) and (\"cls_token\" not in name) :\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c08836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss is 1.8968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 valid acc is 0.63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 loss is 1.3355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 valid acc is 0.65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 loss is 1.1966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 valid acc is 0.66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3 loss is 1.1109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4 loss is 1.0477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5 loss is 0.9865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6 loss is 0.9622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7 loss is 0.9380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8 loss is 0.9207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9 loss is 0.9015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 loss is 0.8859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11 loss is 0.8711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12 loss is 0.8567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13 loss is 0.8426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14 loss is 0.8297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15 loss is 0.8184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16 loss is 0.8055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17 loss is 0.7968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18 loss is 0.7858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18 valid acc is 0.67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19 loss is 0.7768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19 valid acc is 0.67\n"
     ]
    }
   ],
   "source": [
    "train_losses_classhead, val_acc_classhead = train(model, parameters, cifar100_train_loader, cifar100_validation_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4a1269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6346,\n",
       " 0.6479,\n",
       " 0.6582,\n",
       " 0.6656,\n",
       " 0.6692,\n",
       " 0.6698,\n",
       " 0.6732,\n",
       " 0.6716,\n",
       " 0.6735,\n",
       " 0.6714,\n",
       " 0.6737,\n",
       " 0.6714,\n",
       " 0.6727,\n",
       " 0.6712,\n",
       " 0.672,\n",
       " 0.672,\n",
       " 0.6723,\n",
       " 0.6723,\n",
       " 0.6712,\n",
       " 0.6733]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_classhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755782b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_val = validate(model, cifar100_validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802d1243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df92831",
   "metadata": {},
   "source": [
    "This will be used as a base model for the next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a108d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826e977",
   "metadata": {},
   "source": [
    "# Memory Token\n",
    "\n",
    "First we convert our model to a `MemoryCapableViT`. This makes it possible to add new classification heads with memory tokens. It also takes care of the attention masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd42d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit import MemoryCapableViT\n",
    "model = MemoryCapableViT(deepcopy(base_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3df8b",
   "metadata": {},
   "source": [
    "By default, wrapping a `ViTForImageClassification` into `MemoryCapableViT` doesn't change anything apart from some under-the-hood modifications (e.g. class token is inserted at the end instead of the beginning).\n",
    "\n",
    "Let's check whether they are actually equivalent by running the validation again. Note that since `MemoryCapableViT` can have multiple heads, we need to specify which head's output to use. Since we currently have only one head, its index is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12078718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory_val = validate(model, cifar100_validation_loader, output_head=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93688211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14918e03",
   "metadata": {},
   "source": [
    "As expected, this accuracy value is the same as before.\n",
    "\n",
    "For a more rigorous verification, there's a unit test in `test_vit.py` which checks the value of output. You can run all available unit test with `pytest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5e224",
   "metadata": {},
   "source": [
    "## Add new classification head with memory\n",
    "\n",
    "We can now add a new classification head to our model.\n",
    "\n",
    "We will train the new head for INaturalist which has 5089 classes. There will be 4 memory tokens in each self-attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9bc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parameters = model.add_head(memory_tokens=1, num_classes=5089)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d87e3",
   "metadata": {},
   "source": [
    "The new parameters are returned as a list:\n",
    "- The new class token. Shape: `[1, 1, 768]`.\n",
    "- All memory tokens, one for each self-attention layer. We have 12 self-attention layers. Each has shape `[1, memory_tokens, 768]`.\n",
    "- Weights (of size `[100, 768]`) and biases (of size `[100]`) of the new classifier head.\n",
    "\n",
    "Let's print shapes of these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73b828f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([1, 1, 768]),\n",
       " torch.Size([5089, 768]),\n",
       " torch.Size([5089])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.size() for p in new_parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee571940",
   "metadata": {},
   "source": [
    "After calling the `add_head` method, the attention mask will be updated automatically. This makes sure that the old class tokens don't interact with the new class and memory tokens.\n",
    "\n",
    "<img src=\"images/attention-mask.png\" alt=\"Attention Mask Figure\" style=\"width: 500px;\"/>\n",
    "\n",
    "Let's check whether our attention mask matches the table above. Note that we currently have $\\text{INP}$, $\\text{CLS}$, $C_1$ and $M_1$ in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13793524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vit.encoder.layer[0].attention.attention.attention_mask[0, 48:, 48:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051331fe",
   "metadata": {},
   "source": [
    "This attention mask is added to the computed attention scores before the softmax is applied.\n",
    "\n",
    "In self-attention layer, we don't insert the memory tokens while calculating the query. Therefore, memory tokens will not attend to other tokens and they won't be present in the output of the self-attention. This also ensures that the attention scores matrix has the same shape as the attention mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303a676",
   "metadata": {},
   "source": [
    "Let's train the new parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491201d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db7578d2ac84db6bb4560774d7819a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37877fd96e74bbda33559c045bd8d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory_train, memory_validate = train(model, new_parameters, naturalist_train_loader,naturalist_test_loader, output_head=1, total_steps=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf3e4db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mem_val = validate(model, naturalist_test_loader, output_head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6952587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4535080053912348"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c95a2",
   "metadata": {},
   "source": [
    "The performance of the previous head should not be affected thanks to attention masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_val = validate(model, cifar100_validation_loader, output_head=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccfb8ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6733"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95825d2b",
   "metadata": {},
   "source": [
    "# Model Concatenation\n",
    "\n",
    "Suppose that someone else took the same pretrained network and fine-tuned it on another dataset with memory tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e82c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MemoryCapableViT(deepcopy(base_model))\n",
    "new_parameters = model2.add_head(memory_tokens=1, num_classes=365)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_train_places, memory_val_places = train(model2, new_parameters, places_train_loader,places_validation_loader, output_head=1, total_steps = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dba112e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9999175773223636, 1.8372030421382912, 1.8006677927342267]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_train_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b8327cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49816438356164383, 0.5050684931506849, 0.5082739726027398]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_val_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58148567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5082739726027398"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model2, places_validation_loader, output_head=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd105a4",
   "metadata": {},
   "source": [
    "Normally, models exhibit lower performance on the previous dataset after finetuning on a different dataset and separately finetuned models cannot be combined. However, we can achieve all of these with learnable memory method!\n",
    "\n",
    "<img src=\"images/model-concat.png\" alt=\"Model Concatenation Figure\" style=\"width: 600px;\"/>\n",
    "\n",
    "`MemoryCapableViT` offers `concatenate` method. It merges two separately finetuned models. This method operates on the model in-place to use less memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "883db116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.concatenate(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4f14d",
   "metadata": {},
   "source": [
    "The combined model has 3 heads: the first one is the original, trained on CIFAR10; the second one trained on CIFAR100; and finally the third one for MNIST. We can now accoplish all of these tasks with a single model without any performance penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58721b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6733"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, cifar100_validation_loader, output_head=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25f16dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5180972940148407"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, naturalist_train_loader, output_head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aa41d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5082739726027398"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, places_validation_loader, output_head=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2175b",
   "metadata": {},
   "source": [
    "If we inspect the attention mask of the combined model, we should see Table 1 with $\\text{INP}$, $\\text{CLS}$, $C_1$, $M_1$, $C_2$ and $M_2$ columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84022497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, 0., -inf],\n",
       "        [0., 0., -inf, 0., -inf, 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vit.encoder.layer[0].attention.attention.attention_mask[0, 48:, 48:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7690a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/models.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef9c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
